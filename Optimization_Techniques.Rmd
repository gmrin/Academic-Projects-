---
title: "Stats 102A - Homework 4 - Numeric Methods"
author: "Mrinalini Garg"
date: ""
output: html_document
---

3. __Root Finding with Fixed Point Iteration [15 points, 3 points each part]__

Modified version of SPURS chapter 10, section 6, exercise 4.

I have written my own version of fixedpoint_show, which uses ggplot to produce the graphs. The code performs fixed point iteration to find a solution to $f(x) = x$.

I have modified it so that it works better for R Markdown output. Instead of prompting the user to continue, it will perform a number of iterations as specified by the `iter` value in the parameters. I encourage you to read through the code line by line and make sure you understand it.

* Do part (a) using x0 = 1
* Do part (a) using x0 = 3
* Do part (b) using x0 = 2 
* Do part (c) using x0 = 2 
* Do part (d) using x0 = 2, no more than 6 iterations


```{r, error = TRUE}
library(ggplot2)
fixedpoint_show <- function(ftn, x0, iter = 5){
  # applies fixed-point method to find x such that ftn(x) == x
  # df_points is used to track each update
  # it will be used to plot the line segments showing each update
  # each line segment connects the points (x1,y1) to (x2,y2)
  df_points <- data.frame(x1=numeric(0),y1=numeric(0),x2=numeric(0),y2=numeric(0))
  xnew <- x0
  cat("Starting value is:", xnew, "\n")
  # iterate the fixed point algorithm
  for(i in 1:iter){
    xold <- xnew
    xnew <- ftn(xold)
    cat("Next value of x is:", xnew, "\n")

    df_points[2*i-1,] <- c(xold, xold, xold, xnew) # vertical (x1 = x2)
    df_points[2*i,] <- c(xold, xnew, xnew, xnew)   # horizontal (y1 = y2)
  }

  ### use ggplot to plot the function and the segments for each iteration
  # determine the limits to use
  x_start <- min(df_points$x1, df_points$x2, x0 - .1) # start is the min of these values
  x_end <- max(df_points$x1, df_points$x2, x0 + .1)   # end is the max of these values
  
  x <- seq(x_start, x_end, length.out = 200)
  fx <- rep(NA, length(x))
  for (i in seq_along(x)) {
    fx[i] <- ftn(x[i])
  }
  function_data <- data.frame(x, fx)
  
  p <- ggplot(function_data, aes(x = x, y = fx)) + geom_line(colour = "blue", size=1) +  # plot the function
    geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_points) + # plot the segments, we specify that a different data frame is used here
    geom_abline(intercept = 0, slope = 1) # plot the line y = x
  
  print(p) # produce the plot
  return(xnew)
}

## Part a, x0 = 1
f <- function(x) cos(x)
fixedpoint_show(f, 1, iter=10)

## Part a using x0= 3,
fixedpoint_show(f, 3, iter=10)

## Part b using x0= 2
f2 <- function(x) exp(exp(-x))
fixedpoint_show(f2, 2, iter=10)

## Part c using x0= 2
f3 <- function(x) x- log(x)+ exp(-x)
fixedpoint_show(f3, 2, iter=10)


## Part c using x0= 2
f4 <- function(x) x + log(x)- exp(-x)
fixedpoint_show(f4, 2, iter=6)
```

For the last 2 calculations it is not possible to find the root of the given functions using the fixed point iteration method as both the funcations have positive slopes. 

4. __Root Finding with Newton Raphson [25 points, 13 points for writing the code, 3 each for parts a-d]__

Modified version of SPURS chapter 10, section 6, exercise 5.

For this problem, we are implementing the Newton Raphson method for root finding. 

I've written some of the code for you. You'll need to write the rest of the code so it can use ggplot to show the function and lines for each iteration.

You'll probably want to refer to the code for the fixed point iteration. Also pay attention to the example used in the textbook for how the function should be programmed. The function takes a value of x and returns two values: the value of the function, and the value of the derivative at that point. Refer to section 10.3, especially page 176.

Once you have it running, produce graphs for:

* part (a) using x0 = 3
* part (b) using x0 = 2
* part (c) using x0 = 0
* part (d) using x0 = 1.1, 1.3, 1.4, 1.5, 1.6, 1.7 (should be simple. just repeat the command several times )


```{r, error = TRUE, warning= FALSE}
newtonraphson_show <- function(ftn, x0, iter = 5) {
  # applies Newton-Raphson to find x such that ftn(x)[1] == 0
  # ftn is a function of x. it returns two values, f(x) and f'(x)
  # x0 is the starting point
  # df_points is used to track each update
  df_points <- data.frame(x1=numeric(0),y1=numeric(0),x2=numeric(0),y2=numeric(0))
  xnew <- x0
  cat("Starting value is:", xnew, "\n")
  # the algorithm
  for(i in 1:iter){
    xold <- xnew
    f_xold <- ftn(xold)
    xnew <- xold - f_xold[1]/f_xold[2]
    cat("Next x value:", xnew, "\n")

    df_points[2*i-1,] <- c(xold, 0, xold, f_xold) # vertical segment 
    df_points[2*i,] <- c( xnew, 0, xold, f_xold)   # tangent segment 
  }
    ### use ggplot to plot the function and the segments for each iteration
  # determine the limits to use
  x_start <- min(df_points$x1, df_points$x2, x0 - .1) # start is the min of these values
  x_end <- max(df_points$x1, df_points$x2, x0 + .1)   # end is the max of these values
  
  x <- seq(x_start, x_end, length.out = 200)
  fx <- rep(NA, length(x))
  for (i in seq_along(x)) {
    fx[i] <- ftn(x[i])[1]
  }
  function_data <- data.frame(x, fx)
  
  p <- ggplot(function_data, aes(x = x, y = fx)) + geom_line(colour = "blue", size=1) + geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_points) 
  print(p)
    return(xnew)
}


## Part a
# example of how your functions could be written
a <- function(x){
  f <- cos(x) - x   # f(x)
  d <- -sin(x) - 1  # f'(x)
  return(c(f,d))
} 
newtonraphson_show(a, 3, iter = 8)
# after a total of six iterations, my value is  0.7390851

# part (b) using x0 = 2
b <- function(x){
  f <- log(x) - exp(-x)  # f(x)
  d <- 1/x + exp(-x)  # f'(x)
  return(c(f,d))
  } 
newtonraphson_show(b, 2, iter = 8)


# part (c) using x0 = 0
c1 <- function(x){
  f <- x^3 -x -3   # f(x)
  d <- 3*x^(2) - 1 # f'(x)
  return(c(f,d))
} 
newtonraphson_show(c1, 0, iter = 8)


# part (d) using x0 = 1.1, 1.3, 1.4, 1.5, 1.6, 1.7 (should be simple. just repeat the command several times )

d1 <- function(x){
  f <- x^3- 7*x^2 + 14*x -8  # f(x)
  d <- 3*x^(2) - 14*x + 14 # f'(x)
  return(c(f,d))
} 
newtonraphson_show(d1, 1.1, iter = 8)
newtonraphson_show(d1, 1.3, iter = 8)
newtonraphson_show(d1, 1.4, iter = 8)
newtonraphson_show(d1, 1.5, iter = 8)
newtonraphson_show(d1, 1.6, iter = 8)
newtonraphson_show(d1, 1.7, iter = 8)
```


5. __Root Finding with Secant Method [20 points for completing the code and graph]__

Modified version of SPURS chapter 10, section 6, exercise 6.

Implement the secant method for root finding. Write a function called `secant_show` similar to the `newtonraphson_show` and `fixedpoint_show` functions. In your function, perform iterations of the algorithm and plot the results. It should behave in a very similar fashion to `newtonraphson_show`.

A framework of the function has been provided. It will take 4 inputs:

* The function. It takes a value of x and returns the value of f(x). (no need to return the derivative)
* x0 The x-value at iteration 0
* x1 The x-value at iteration 1. The secant uses the last two values, and draws a secant line that connects those until that secant line intersects the x-axis.
* the number of iterations to perform

While non-trivial, I do believe that the previous examples will provide a good guide for writing your code.

Once complete, use your function to find the root of $log(x) - exp(-x)$ using $x_0 = 1$ and $x_1 = 2$.

Also find the root of $x^2 - 0.5$ using $x_0 = 4$ and $x_1 = 3.5$.


```{r}
secant_show <- function(ftn, x0, x1, iter = 5) {

  # ftn is a function of x. it returns two values, f(x) and f'(x)
  df_points <- data.frame(x1=numeric(0),y1=numeric(0),x2=numeric(0),y2=numeric(0))
  xa <- x0
  xb<- x1
  xnew<- xb
  # 
  cat("Starting values are:", xa, "and", xb,  "\n")
  # the algorithm
  for(i in 1:iter){
    if( i != 1){
    xa<- xb
    xb<- xnew 
    }
    f_xa<- ftn(xa)
    f_xb<- ftn(xb)
    xnew<- xa- f_xa*((xb- xa)/(f_xb- f_xa)) 
    cat("Next x value is:", xnew, "\n")

    df_points[4*i-3,] <- c(xa, 0, xa, f_xa) # vertical segment1 
    df_points[4*i-2,] <- c( xb, 0, xb, f_xb)   # vertical segment 2
    df_points[4*i-1,]  <-  c( xa, f_xa, xb, f_xb) # Secant segment 
     df_points[4*i,]  <-  c( xnew, 0, xb, f_xb) # Secant segment full
    }
  
    ### use ggplot to plot the function and the segments for each iteration
  # determine the limits to use
  x_start <- min(df_points$x1, df_points$x2, x0 - .1) # start is the min of these values
  x_end <- max(df_points$x1, df_points$x2, x0 + .1)   # end is the max of these values
  
  x <- seq(x_start, x_end, length.out = 200)
  fx <- rep(NA, length(x))
  for (i in seq_along(x)) {
    fx[i] <- ftn(x[i])
  }
  function_data <- data.frame(x, fx)
  
  p <- ggplot(function_data, aes(x = x, y = fx)) + geom_line(colour = "blue", size=1) + geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_points) 
  print(p)
    return(xnew)
}

## Part a
a <- function(x){
  f <- log(x) - exp(-x) # f(x)
  return(f)
} 
secant_show(a, 1,2, iter = 8 )


## Part b

b <- function(x){
  f <- x^2 - 0.5# f(x)
  return(f)
} 
secant_show(b, 4, 3.5, iter = 8)

```


6. __Coordinate Descent Algorithm for Optimization [25 points]__

Coordinate descent is an optimization algorithm. It can be used to find a local minimum of a function. To perform coordinate descent, you perform a line search along one coordinate direction to find the value that minimizes the function in that direction while the other values are held constant. Once the value for that direction is updated, you perform the same operation for the other coordinate directions. This repeats until it has been updated for all coordinate directions, at which point the cycle repeats.

Thus for a function of two variables $f(x,y)$, a simple version of the algorithm can be described as follows:

1) Start with some initial values of $x$ and $y$. This is time 0, so we have $x^{(0)}$ and $y^{(0)}$.
2) Iterate:
    1) Update $x^{(t+1)}$ to be the value of $x$ that minimizes $f(x,y = y^{(t)})$
    2) Update $y^{(t+1)}$ to be the value of $y$ that minimizes $f(x = x^{(t+1)},y)$
3) Stop when some convergence criterion has been met.

The "tricky" part of the algorithm is finding the value that minimizes the function along one of the directions. 

__Golden Section Search Method (with Video)__
This unidimensional minimization be done in one of many ways, but for our purposes, we will use the golden section search method.

The premise of how the golden section search works is summarized very nicely in this video from CUBoulderComputing: https://vimeo.com/86277921

I will provide the code for the golden section search method here. This is a modified version of Eric Cai's code (https://chemicalstatistician.wordpress.com). It has been modified so that the locations of x1 and x2 match the CUBoulderComputing video

```{r}
##### A modifcation of code provided by Eric Cai
golden = function(f, lower, upper, tolerance = 1e-5)
{
   golden.ratio = 2/(sqrt(5) + 1)

   ## Use the golden ratio to find the initial test points
   x1 <- lower + golden.ratio * (upper - lower)
   x2 <- upper - golden.ratio * (upper - lower)
   
   ## the arrangement of points is:
   ## lower ----- x2 --- x1 ----- upper

   ### Evaluate the function at the test points
   f1 <- f(x1)
   f2 <- f(x2)

   while (abs(upper - lower) > tolerance) {
        if (f2 > f1) {
        # the minimum is to the right of x2
        lower <- x2  # x2 becomes the new lower bound
        x2 <- x1     # x1 becomes the new x2
        f2 <- f1     # f(x1) now becomes f(x2)
        x1 <- lower + golden.ratio * (upper - lower)  
        f1 <- f(x1)  # calculate new x1 and f(x1)
        } else {
        # then the minimum is to the left of x1
        upper <- x1  # x1 becomes the new upper bound
        x1 <- x2     # x2 becomes the new x1
        f1 <- f2
        x2 <- upper - golden.ratio * (upper - lower)
        f2 <- f(x2)  # calculate new x2 and f(x2)
        }
    }
    (lower + upper)/2 # the returned value is the midpoint of the bounds
}
```

We can thus use the golden search to find the minimizing value of a function. For example, the function $f(x) = (x - 3)^2$ has a minimum value at $x = 3$.

```{r}
f <- function(x){ (x - 3)^2 }
golden(f, 0, 10)
```

__Back to Coordinate Descent__

With our golden search function, we can now create our coordinate descent algorithm:

1) Start with some initial values of $x$ and $y$. This is time 0, so we have $x^{(0)}$ and $y^{(0)}$.
2) Iterate:
    1) Update $x$:
        a. Find the function $f(x) = f(x,y = y^{(t)})$
        b. Use golden search to minimize $f(x)$
        c. Set $x^{(t+1)}$ be the result of the search.
    2) Update $y$
        a. Find the function $f(y) = f(x = x^{(t+1)},y)$
        b. Use golden search to minimize $f(y)$
        c. Set $y^{(t+1)}$ be the result of the search.
3) Stop when some convergence criterion has been met.

__Code to perform coordinate descent to minimize the following function:__

$$g(x,y) = 5 x ^ 2 - 6 x y + 5 y ^ 2$$

```{r}
g <- function(x,y) { 
    5 * x ^ 2 - 6 * x * y + 5 * y ^ 2
}
x <- seq(-1.5,1, len=100)
y <- seq(-1.5,1, len=100)
```

#Performing coordinate descent

```{r}
#PLotting using the contour function 
z <- outer(x,y,g)
contour(x,y,z, levels = seq(.5,5,by=.9)) # code to plot contour lines

x_i <- -1.5
y_i <- -1.5

  for( i in 1:15){
  gx<- function(x=x_i) 5 * x ^ 2 - 6 * x * y_i + 5 * y_i ^ 2
  x_n<- golden(gx, lower= -1.5, upper= 1.5)
  xo<- x_i
  x_i<- x_n  
  gy<- function(y=y_i) 5 * x_i ^ 2 - 6 * x_i * y + 5 * y ^ 2 
  y_n<- golden(gy, lower= -1.5, upper= 1.5)
  yo<- y_i
  y_i<- y_n
print(c( x_i, y_i))
lines(c(xo, x_i, x_i), c(yo,yo,y_i), col = "blue")

if ( abs(x_i- xo) < 1e-5){ 
  cat(" Early termination since the difference between x and the next x is less than the tolerance value.")
  break
}
  }

```


  